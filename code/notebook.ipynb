{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScHwA7427San",
        "outputId": "df27513a-1760-4156-8e46-6cd4537d3633",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "print(matplotlib.get_backend())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7OvPIb77b6g",
        "outputId": "068ff9eb-1677-4f55-927e-b7fbd0ee0505"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module://matplotlib_inline.backend_inline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "tctHUDfR7fsk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH8E4mis4oAr",
        "outputId": "f8b1ecb6-1077-4cab-aa4e-402602dad166"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FAJkNaMx7Saq",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Lab7_Benyahia_Mohamed/code/data/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvQ4jM9M70Uz",
        "outputId": "ebc10373-c0db-4f71-a8ce-ae2c196f9dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 6.2614 time: 3.1501s\n",
            "Epoch: 0002 loss_train: 5.5464 time: 2.4351s\n",
            "Epoch: 0003 loss_train: 5.5409 time: 2.9976s\n",
            "Epoch: 0004 loss_train: 5.5309 time: 2.5302s\n",
            "Epoch: 0005 loss_train: 5.5310 time: 2.4284s\n",
            "Epoch: 0006 loss_train: 5.5259 time: 2.3890s\n",
            "Epoch: 0007 loss_train: 5.5232 time: 2.4124s\n",
            "Epoch: 0008 loss_train: 5.5233 time: 2.7577s\n",
            "Epoch: 0009 loss_train: 5.5206 time: 2.7153s\n",
            "Epoch: 0010 loss_train: 5.5217 time: 2.4460s\n",
            "Epoch: 0011 loss_train: 5.5155 time: 2.4689s\n",
            "Epoch: 0012 loss_train: 5.5169 time: 2.4154s\n",
            "Epoch: 0013 loss_train: 5.5148 time: 2.6633s\n",
            "Epoch: 0014 loss_train: 5.5152 time: 2.8760s\n",
            "Epoch: 0015 loss_train: 5.5143 time: 2.4241s\n",
            "Epoch: 0016 loss_train: 5.5145 time: 2.4292s\n",
            "Epoch: 0017 loss_train: 5.5153 time: 2.4546s\n",
            "Epoch: 0018 loss_train: 5.5146 time: 2.5783s\n",
            "Epoch: 0019 loss_train: 5.5139 time: 3.0085s\n",
            "Epoch: 0020 loss_train: 5.5126 time: 2.4762s\n",
            "Finished training for DeepSets model\n",
            "\n",
            "Epoch: 0001 loss_train: 14.2691 time: 3.7173s\n",
            "Epoch: 0002 loss_train: 1.7030 time: 3.6895s\n",
            "Epoch: 0003 loss_train: 1.0165 time: 4.4489s\n",
            "Epoch: 0004 loss_train: 0.9140 time: 3.6718s\n",
            "Epoch: 0005 loss_train: 0.8965 time: 3.6413s\n",
            "Epoch: 0006 loss_train: 0.8936 time: 4.2641s\n",
            "Epoch: 0007 loss_train: 0.8756 time: 3.9622s\n",
            "Epoch: 0008 loss_train: 0.8722 time: 3.6225s\n",
            "Epoch: 0009 loss_train: 0.8692 time: 3.6986s\n",
            "Epoch: 0010 loss_train: 0.8570 time: 4.5295s\n",
            "Epoch: 0011 loss_train: 0.8547 time: 3.6674s\n",
            "Epoch: 0012 loss_train: 0.8583 time: 3.6353s\n",
            "Epoch: 0013 loss_train: 0.8443 time: 4.2673s\n",
            "Epoch: 0014 loss_train: 0.8490 time: 3.8941s\n",
            "Epoch: 0015 loss_train: 0.8465 time: 3.6581s\n",
            "Epoch: 0016 loss_train: 0.8410 time: 3.7065s\n",
            "Epoch: 0017 loss_train: 0.8423 time: 4.4495s\n",
            "Epoch: 0018 loss_train: 0.8383 time: 3.6738s\n",
            "Epoch: 0019 loss_train: 0.8383 time: 3.6522s\n",
            "Epoch: 0020 loss_train: 0.8338 time: 4.3136s\n",
            "Finished training for LSTM model\n"
          ]
        }
      ],
      "source": [
        "!python '/content/drive/MyDrive/Lab7_Benyahia_Mohamed/code/part1/train.py'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "!python '/content/drive/MyDrive/Lab7_Benyahia_Mohamed/code/part1/eval.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A67poJOCUh-",
        "outputId": "c28fceb7-8fc0-4b47-a38e-a50d8128c6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DeepSets checkpoint!\n",
            "/content/drive/MyDrive/Lab7_Benyahia_Mohamed/code/part1/eval.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('model_deepsets.pth.tar')\n",
            "Loading LSTM checkpoint!\n",
            "/content/drive/MyDrive/Lab7_Benyahia_Mohamed/code/part1/eval.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('model_lstm.pth.tar')\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/Lab7_Benyahia_Mohamed/code/part2/main.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ULl5TNY4eCf",
        "outputId": "2aca4d52-d3c7-41d0-da40-3a7ccec5d3d2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Lab7_Benyahia_Mohamed/code/part2/utils.py:27: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
            "  return torch.sparse.FloatTensor(indices, values, shape)\n",
            "Epoch: 0005, Train Loss: 673.29205, Train Reconstruction Loss: 672.86, Train KLD Loss: 8.56, Val Loss: 675.78455, Val Reconstruction Loss: 675.35, Val KLD Loss: 8.65\n",
            "Epoch: 0010, Train Loss: 671.01801, Train Reconstruction Loss: 670.76, Train KLD Loss: 5.08, Val Loss: 674.30457, Val Reconstruction Loss: 674.06, Val KLD Loss: 4.84\n",
            "Epoch: 0015, Train Loss: 670.93640, Train Reconstruction Loss: 670.40, Train KLD Loss: 10.68, Val Loss: 674.74139, Val Reconstruction Loss: 673.80, Val KLD Loss: 18.81\n",
            "Epoch: 0020, Train Loss: 670.45154, Train Reconstruction Loss: 670.13, Train KLD Loss: 6.37, Val Loss: 673.93060, Val Reconstruction Loss: 673.71, Val KLD Loss: 4.49\n",
            "Epoch: 0025, Train Loss: 669.97723, Train Reconstruction Loss: 669.79, Train KLD Loss: 3.79, Val Loss: 673.21741, Val Reconstruction Loss: 672.97, Val KLD Loss: 4.94\n",
            "Epoch: 0030, Train Loss: 660.63947, Train Reconstruction Loss: 660.10, Train KLD Loss: 10.85, Val Loss: 661.90021, Val Reconstruction Loss: 661.34, Val KLD Loss: 11.29\n",
            "Epoch: 0035, Train Loss: 652.62836, Train Reconstruction Loss: 651.78, Train KLD Loss: 16.89, Val Loss: 656.42529, Val Reconstruction Loss: 655.59, Val KLD Loss: 16.66\n",
            "Epoch: 0040, Train Loss: 650.40887, Train Reconstruction Loss: 649.54, Train KLD Loss: 17.41, Val Loss: 653.71960, Val Reconstruction Loss: 652.83, Val KLD Loss: 17.72\n",
            "Epoch: 0045, Train Loss: 649.82758, Train Reconstruction Loss: 648.99, Train KLD Loss: 16.70, Val Loss: 652.59247, Val Reconstruction Loss: 651.70, Val KLD Loss: 17.84\n",
            "Epoch: 0050, Train Loss: 648.64362, Train Reconstruction Loss: 647.77, Train KLD Loss: 17.41, Val Loss: 651.50256, Val Reconstruction Loss: 650.60, Val KLD Loss: 18.05\n",
            "Epoch: 0055, Train Loss: 648.63409, Train Reconstruction Loss: 647.82, Train KLD Loss: 16.29, Val Loss: 654.23865, Val Reconstruction Loss: 653.29, Val KLD Loss: 18.88\n",
            "Epoch: 0060, Train Loss: 648.03308, Train Reconstruction Loss: 647.17, Train KLD Loss: 17.17, Val Loss: 651.44409, Val Reconstruction Loss: 650.64, Val KLD Loss: 16.08\n",
            "Epoch: 0065, Train Loss: 647.28589, Train Reconstruction Loss: 646.49, Train KLD Loss: 16.01, Val Loss: 650.40143, Val Reconstruction Loss: 649.59, Val KLD Loss: 16.31\n",
            "Epoch: 0070, Train Loss: 646.95496, Train Reconstruction Loss: 646.18, Train KLD Loss: 15.51, Val Loss: 649.62140, Val Reconstruction Loss: 648.80, Val KLD Loss: 16.39\n",
            "Epoch: 0075, Train Loss: 646.79944, Train Reconstruction Loss: 645.98, Train KLD Loss: 16.41, Val Loss: 650.73877, Val Reconstruction Loss: 649.90, Val KLD Loss: 16.85\n",
            "Epoch: 0080, Train Loss: 646.34705, Train Reconstruction Loss: 645.57, Train KLD Loss: 15.54, Val Loss: 648.95935, Val Reconstruction Loss: 648.19, Val KLD Loss: 15.29\n",
            "Epoch: 0085, Train Loss: 646.45007, Train Reconstruction Loss: 645.61, Train KLD Loss: 16.83, Val Loss: 649.85022, Val Reconstruction Loss: 648.94, Val KLD Loss: 18.15\n",
            "Epoch: 0090, Train Loss: 646.04541, Train Reconstruction Loss: 645.27, Train KLD Loss: 15.46, Val Loss: 649.26642, Val Reconstruction Loss: 648.43, Val KLD Loss: 16.83\n",
            "Epoch: 0095, Train Loss: 645.49072, Train Reconstruction Loss: 644.71, Train KLD Loss: 15.59, Val Loss: 648.76447, Val Reconstruction Loss: 647.99, Val KLD Loss: 15.51\n",
            "Epoch: 0100, Train Loss: 644.81946, Train Reconstruction Loss: 644.05, Train KLD Loss: 15.36, Val Loss: 648.67725, Val Reconstruction Loss: 647.91, Val KLD Loss: 15.35\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}